{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "from dataset_generator import generate_dpo_dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = 'CARS'\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"dpo_training.ipynb\"\n",
    "\n",
    "dataset_path = \"altas-ai/corrective_dataset_MATH_LLAMA3_8b_ZeroShot_COT\"\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "#prompt = \"{problem} \\nPlease reason step by step, and put your final answer within \\\\boxed{{}}.\\nApproach: \"\n",
    "dataset = load_dataset(dataset_path)\n",
    "split = dataset['train'].train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = split['train']\n",
    "eval_dataset = split['test']\n",
    "\n",
    "# Rename columns\n",
    "train_dataset = train_dataset.rename_column(\"original_prompt\", \"prompt\")\n",
    "train_dataset = train_dataset.rename_column(\"incorrect_completion\", \"rejected\")\n",
    "train_dataset = train_dataset.rename_column(\"correct_completion\", \"chosen\")\n",
    "\n",
    "eval_dataset = eval_dataset.rename_column(\"original_prompt\", \"prompt\")\n",
    "eval_dataset = eval_dataset.rename_column(\"incorrect_completion\", \"rejected\")\n",
    "eval_dataset = eval_dataset.rename_column(\"correct_completion\", \"chosen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth: Fast Llama patching release 2024.7\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3080 Ti Laptop GPU. Max memory: 15.732 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2024.7 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_path,\n",
    "    load_in_4bit = True,\n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8,\n",
    "    #target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "    #                  \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    #target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_alpha = 16,    \n",
    "    lora_dropout = 0, # Dropout = 0 is currently optimized\n",
    "    bias = \"none\",    # Bias = \"none\" is currently optimized\n",
    "    use_gradient_checkpointing = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2121/2121 [00:03<00:00, 676.19 examples/s]\n",
      "Map: 100%|██████████| 531/531 [00:00<00:00, 693.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model = model,\n",
    "    ref_model = None,\n",
    "    args=DPOConfig(\n",
    "        output_dir=\"models\",\n",
    "\n",
    "        num_train_epochs=1,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=1,\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        beta=0.1,\n",
    "        \n",
    "        gradient_accumulation_steps=4, \n",
    "        eval_accumulation_steps=4,\n",
    "        gradient_checkpointing=True,\n",
    "        \n",
    "        max_length=2048,\n",
    "        max_prompt_length=1024,\n",
    "        max_target_length=1024,\n",
    "        remove_unused_columns=False,\n",
    "        truncation_mode=\"keep_start\",\n",
    "        \n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=3,\n",
    "        report_to=\"wandb\",\n",
    "        run_name=\"DPO_2\",\n",
    "        bf16 = True,\n",
    "    ),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 2,121 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 4 | Total steps = 530\n",
      " \"-____-\"     Number of trainable parameters = 3,407,872\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmark-chen-next\u001b[0m (\u001b[33mteam-quantum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mark/Documents/AIMO/wandb/run-20240712_232257-rf3focpb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/team-quantum/CARS/runs/rf3focpb' target=\"_blank\">DPO_2</a></strong> to <a href='https://wandb.ai/team-quantum/CARS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/team-quantum/CARS' target=\"_blank\">https://wandb.ai/team-quantum/CARS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/team-quantum/CARS/runs/rf3focpb' target=\"_blank\">https://wandb.ai/team-quantum/CARS/runs/rf3focpb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/530 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "  0%|          | 1/530 [00:06<54:28,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6931, 'grad_norm': 3.0271146297454834, 'learning_rate': 4.9905660377358493e-05, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -95.05059814453125, 'logps/chosen': -93.76498413085938, 'logits/rejected': 0.3297100365161896, 'logits/chosen': 0.2812022268772125, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/530 [00:11<51:06,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6907, 'grad_norm': 4.685053825378418, 'learning_rate': 4.9811320754716985e-05, 'rewards/chosen': 0.004506874363869429, 'rewards/rejected': -0.0017758364556357265, 'rewards/accuracies': 0.75, 'rewards/margins': 0.006282712332904339, 'logps/rejected': -116.45826721191406, 'logps/chosen': -131.8994140625, 'logits/rejected': 0.05328919738531113, 'logits/chosen': -0.044286224991083145, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/530 [00:20<1:03:40,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6801, 'grad_norm': 5.621777057647705, 'learning_rate': 4.9716981132075476e-05, 'rewards/chosen': 0.001522732200101018, 'rewards/rejected': -0.02511920966207981, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02664194256067276, 'logps/rejected': -95.37469482421875, 'logps/chosen': -95.34652709960938, 'logits/rejected': 0.29182183742523193, 'logits/chosen': 0.2353961169719696, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/530 [00:32<1:19:11,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.711, 'grad_norm': 4.914802551269531, 'learning_rate': 4.962264150943397e-05, 'rewards/chosen': -0.0047508240677416325, 'rewards/rejected': 0.03016681969165802, 'rewards/accuracies': 0.25, 'rewards/margins': -0.034917641431093216, 'logps/rejected': -141.12496948242188, 'logps/chosen': -139.4482879638672, 'logits/rejected': 0.7066179513931274, 'logits/chosen': 0.4385793209075928, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/530 [00:39<1:11:56,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7084, 'grad_norm': 3.577291488647461, 'learning_rate': 4.952830188679246e-05, 'rewards/chosen': -0.032563209533691406, 'rewards/rejected': -0.002468680962920189, 'rewards/accuracies': 0.25, 'rewards/margins': -0.030094526708126068, 'logps/rejected': -121.73657989501953, 'logps/chosen': -135.8009033203125, 'logits/rejected': 0.12698335945606232, 'logits/chosen': 0.035148195922374725, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/530 [00:45<1:06:28,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6714, 'grad_norm': 3.205763101577759, 'learning_rate': 4.943396226415095e-05, 'rewards/chosen': 0.021212007850408554, 'rewards/rejected': -0.023925019428133965, 'rewards/accuracies': 0.75, 'rewards/margins': 0.04513702541589737, 'logps/rejected': -80.84663391113281, 'logps/chosen': -123.96571350097656, 'logits/rejected': 0.04646002873778343, 'logits/chosen': 0.014243833720684052, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/530 [00:51<1:01:36,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.679, 'grad_norm': 3.9472076892852783, 'learning_rate': 4.933962264150943e-05, 'rewards/chosen': -0.003227042267099023, 'rewards/rejected': -0.03255443647503853, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02932739444077015, 'logps/rejected': -101.75228881835938, 'logps/chosen': -116.02317810058594, 'logits/rejected': 0.24350719153881073, 'logits/chosen': 0.3324413001537323, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/530 [00:59<1:03:10,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.649, 'grad_norm': 3.621281147003174, 'learning_rate': 4.9245283018867924e-05, 'rewards/chosen': 0.031432151794433594, 'rewards/rejected': -0.059331707656383514, 'rewards/accuracies': 1.0, 'rewards/margins': 0.09076385945081711, 'logps/rejected': -75.12834167480469, 'logps/chosen': -76.53816986083984, 'logits/rejected': 0.415519118309021, 'logits/chosen': 0.07967068254947662, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/530 [01:05<1:00:15,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6903, 'grad_norm': 3.58050537109375, 'learning_rate': 4.9150943396226415e-05, 'rewards/chosen': -0.021831704303622246, 'rewards/rejected': -0.02833118475973606, 'rewards/accuracies': 0.25, 'rewards/margins': 0.006499480921775103, 'logps/rejected': -110.13899230957031, 'logps/chosen': -139.6927032470703, 'logits/rejected': -0.07249025255441666, 'logits/chosen': -0.10604231804609299, 'epoch': 0.02}\n"
     ]
    }
   ],
   "source": [
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
