{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_MATH_dataset, get_GSM8k_dataset\n",
    "from dataset_generator import (\n",
    "    generate_completion_dataset,\n",
    "    generate_corrective_dataset,\n",
    "    generate_kto_dataset,\n",
    "    generate_copy_dataset,\n",
    ")\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "import re\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    ")\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, quantization_config=quantization_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "generate_kargs = {\"max_new_tokens\": 3000, \"do_sample\": True, \"batch_size\": 2}\n",
    "\n",
    "prompt = \"{problem} \\nPlease reason step by step, and put your final answer within \\\\boxed{{}}\"\n",
    "corrective_prompt = \"{problem}\\nHere is the incorrect solution of the problem.\\n{incorrect_solution}\\nHere is the answer got from the incorrect solution: {incorrect_answer}, Here is the correct answer of the problem.\\n{correct_answer}\\nPlease based on the incorrect solution and the correct answer, provide the correct solution of the problem by reasoning step by step and put your final answer within \\\\boxed{{}}\"\n",
    "corrective_prompt_v2 = \"\"\"\n",
    "Here is the problem: {problem}\n",
    "Here is the answer got from the incorrect solution: {incorrect_answer}\n",
    "You are a smart and talented math professor, please reason step by step, and put your final answer within \\\\boxed{{}} following the output format of the incorrect solution.\n",
    "Output format:\n",
    "\\\\boxed{{your answer}}\n",
    "\"\"\"\n",
    "dataset = get_GSM8k_dataset().select(range(2))\n",
    "\n",
    "copy_prompt = \"\"\"\n",
    "Problem: {problem}\n",
    "Correct Solution: {correct_solution}\n",
    "Incorrect Solution: {incorrect_solution}\n",
    "This is the problem and the correct and incorrect solution generated by LLM. Please generate a similar problem with a correct solution and an incorrect solution in the following format:\n",
    "\n",
    "Problem:\n",
    "\"\"\"\n",
    "def extract_prompt_correct_incorrect(text):\n",
    "    pattern = re.compile(\n",
    "        r\"Problem:\\s*(?P<problem>.+?)\\n\"\n",
    "        r\"Correct Solution:\\s*(?P<correct_solution>.+?)\\n\"\n",
    "        r\"Incorrect Solution:\\s*(?P<incorrect_solution>.+?)\\n\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "    \n",
    "    match = pattern.search(text)\n",
    "    if match:\n",
    "        return match.group(\"problem\"), match.group(\"correct_solution\"), match.group(\"incorrect_solution\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_answer_from_output(text):\n",
    "    try:\n",
    "        result_output = re.findall(r\"\\\\boxed\\{(\\d+)\\}\", text)\n",
    "        return float(result_output[0])\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_dataset = generate_completion_dataset(\n",
    "    pipe,\n",
    "    dataset,\n",
    "    prompt,\n",
    "    get_answer_from_output,\n",
    "    generate_kwargs=generate_kargs,\n",
    "    generate_count_per_problem=1,\n",
    ")\n",
    "completion_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_dataset = completion_dataset.filter(lambda x: x[\"label\"] is False)\n",
    "corrective_dataset, history = generate_corrective_dataset(\n",
    "    incorrect_dataset,\n",
    "    corrective_prompt,\n",
    "    pipe,\n",
    "    get_answer_from_output,\n",
    "    generate_kwargs=generate_kargs,\n",
    "    corrective_solution_count_per_incorrect_solution=1,\n",
    "    return_completion_history=True,\n",
    ")\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of generate_copy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "example_corrective_dataset = Dataset.from_dict({\n",
    "    \"problem\": [\"What is the value of $\\\\frac{1}{2} + \\\\frac{1}{3}$?\"],\n",
    "    \"correct_completion\": [\"$\\\\frac{1}{2} + \\\\frac{1}{3} = \\\\frac{3}{6} + \\\\frac{2}{6} = \\\\frac{5}{6}$\"],\n",
    "    \"incorrect_completion\": [\"$\\\\frac{1}{2} + \\\\frac{1}{3} = \\\\frac{1+1}{2+3} = \\\\frac{2}{5}$\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_dataset = generate_copy_dataset(\n",
    "    example_corrective_dataset,\n",
    "    copy_prompt,\n",
    "    pipe,\n",
    "    1,\n",
    "    extract_problem_correct_incorrect=extract_prompt_correct_incorrect,\n",
    "    generate_kwargs=generate_kargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_dataset[:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
