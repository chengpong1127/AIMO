{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage3: Generate corrective dataset from completion dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline, StoppingCriteria, StoppingCriteriaList\n",
    "def get_pipe(model_path: str):\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path, quantization_config=quantization_config\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from dataset_generator import generate_corrective_dataset\n",
    "import re\n",
    "\n",
    "completion_dataset_path = \"dataset/completion_dataset_MATH_LLAMA3_8b_ZeroShot_COT_checkpoint copy\"\n",
    "model_path = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "dataset_save_path = \"dataset/corrective_dataset_MATH_LLAMA3_8b_ZeroShot_COT\"\n",
    "corrective_prompt = \"\"\"{problem}\n",
    "Here is the incorrect solution generated from LLM.\n",
    "{incorrect_solution}, The answer we got from the incorrect solution is {incorrect_answer}. Note that if the incorrect answer is None, it means the model did not generate answer following the format.\n",
    "Here is the correct answer of this problem: {correct_answer}.\n",
    "You are a smart and talented math professor, you need to correct the incorrect solution that can lead to the correct answer.\n",
    "Please reason step by step, and put your final answer within \\\\boxed{{}}.\n",
    "Approach: \"\"\"\n",
    "\n",
    "def get_answer_from_output(text):\n",
    "    try:\n",
    "        result_output = re.findall(r\"\\\\boxed\\{(\\d+)\\}\", text)\n",
    "        return float(result_output[-1])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "    def __call__(self, input_ids, scores):\n",
    "        decoded_text = pipe.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        decoded_text = decoded_text[-20:]\n",
    "        return re.search(r\"\\\\boxed\\{(.+)\\}\", decoded_text) is not None\n",
    "\n",
    "generate_kargs = {\n",
    "    \"max_new_tokens\": 2048,\n",
    "    \"do_sample\": True, \n",
    "    \"batch_size\": 4,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"temperature\": 0.5,\n",
    "    \"stopping_criteria\" : StoppingCriteriaList([StoppingCriteriaSub()]),\n",
    "}\n",
    "\n",
    "pipe = get_pipe(model_path)\n",
    "completion_dataset = load_from_disk(completion_dataset_path)\n",
    "incorrect_dataset = completion_dataset.filter(lambda x: x[\"label\"] is False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrective_dataset, history = generate_corrective_dataset(\n",
    "    incorrect_solution_dataset=incorrect_dataset,\n",
    "    corrective_prompt=corrective_prompt,\n",
    "    supervisor_pipe=pipe,\n",
    "    extract_answer_function=get_answer_from_output,\n",
    "    generate_kwargs=generate_kargs,\n",
    "    corrective_solution_count_per_incorrect_solution=1,\n",
    "    correction_attempts=5,\n",
    "    return_completion_history=True,\n",
    "    checkpoint_path=\"_\".join([dataset_save_path, \"checkpoint\"]),\n",
    ")\n",
    "corrective_dataset.save_to_disk(dataset_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
